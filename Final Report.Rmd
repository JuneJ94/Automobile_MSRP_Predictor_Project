---
title: 'STAT 420: Final Project Report'
authors: "Team"
output:
  pdf_document:
    toc: yes
  html_document:
    theme: readable
    toc: yes
---



##Installing packages (commented out) and loading libraries for future use.
```{r}
#install.packages("mltools")
#install.packages("caret")
#install.packages("dplyr")
#install.packages("ggplots2")
library(mltools)
library(data.table)
library(knitr)
```


**Loading dataset in R from the CSV file, and removing some columns which are not needed**
```{r}
car_data = read.csv("Cars_data.csv")
car_data = subset(car_data, select = -c(Vehicle.Style, Market.Category))
car_data = na.omit(car_data)

#unique(car_data$Transmission.Type)
#colnames(car_data)
#unique(car_data$Engine.Fuel.Type)
#unique(car_data$Driven_Wheels)
#unique(car_data$Vehicle.Size)
#car_data$Make<-NULL
car_data$Model<- NULL
car_data_info = car_data
#head(car_data)

```


##Dataset Overview:

**The dataset car_data now contains the following variables:**

xx
xx
xx
xx





##Engineering the data

```{r}
hist( car_data$MSRP, scien = FALSE, col = "lightblue")
```


**Removing extreme prices less than $10,000 and greater than $100,000**

We decided to do this since there were certain extreme outliers as visible in the graph above. 
```{r}

car_data_priced<-car_data[!(car_data$MSRP>100000 | car_data$MSRP< 10000 ),]
range(car_data_priced$MSRP)

```


Once this is done, the MSRP Histogram looks like:

```{r}
hist( car_data_priced$MSRP, scientific = FALSE, col = "lightpink")
```

**This is a reasonable distribution for our response variable. Additionally, price is a much more important factor in the expensive/luxury segment than in the mass market -  https://smallbusiness.chron.com/price-sensitivity-product-65805.html**



**Removing the non automatic/manual transmission types, and storing this new data in car_data_transd dataframe**

This is done for simplicity. There are very few automobiles with non automatic/manual transmissions, so our model would not be accurate at predicting these.

```{r}


car_data_transd<-car_data_priced[!(car_data_priced$Transmission.Type=="AUTOMATED_MANUAL" | car_data_priced$Transmission.Type=="DIRECT_DRIVE" | car_data_priced$Transmission.Type=="UNKNOWN"),]

unique(car_data_transd$Transmission.Type)

```



**Removing certain fuel types, keeping only gasoline and diesel. Storing the result in car_data_fuel dataframe**

This is done for simplicity when it came to predictors. We have a large dataset, so we can afford to omit certain types of automobiles. Additionally, since there were only few of non gasoline/diesel vehicles and we are targeting the mass market, this makes sense. We understand that the electric car segment is growing, and a more up-to-date dataset (this one spans all the way from 1990 to 2017) would help us cater to that market.

```{r}
car_data_fuel<-car_data_transd[!(grepl("flex", car_data_transd$Engine.Fuel.Type, fixed = TRUE)
|car_data_transd$Engine.Fuel.Type=="electric" | car_data_transd$Engine.Fuel.Type=="" | car_data_transd$Engine.Fuel.Type=="natural gas"),]

unique(car_data_fuel$Engine.Fuel.Type)
```


**Assigning the different types of gasoline to a single "gasoline value". Now, the only two values for fuel type will be "gasoline" and "diesel" as visible below**

Here, we combine the different types of gasoline into one.

```{r}
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "premium unleaded (required)" ] <- "gasoline"
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "regular unleaded" ] <- "gasoline"
car_data_fuel$Engine.Fuel.Type[car_data_fuel$Engine.Fuel.Type == "premium unleaded (recommended)" ] <- "gasoline"

unique(car_data_fuel$Engine.Fuel.Type)

```



**Making categorical variables factors, and adding age variable**

**The agevariable is essentially how many years ago the model was released. It is the "Year" in the dataset subtracted from the current year**
```{r}
car_data_factored = car_data_fuel
car_data_factored$Vehicle.Size <- factor(car_data_factored$Vehicle.Size)
car_data_factored$Transmission.Type <- factor(car_data_factored$Transmission.Type)
car_data_factored$Engine.Fuel.Type <- factor(car_data_factored$Engine.Fuel.Type)
car_data_factored$Driven_Wheels <- factor(car_data_factored$Driven_Wheels)
car_data_factored$Engine.Cylinders <- factor(car_data_factored$Engine.Cylinders)
car_data_factored$Number.of.Doors <- factor(car_data_factored$Number.of.Doors)
car_data_factored$Make <- factor(car_data_factored$Make)

levels(car_data_factored$Vehicle.Size)
levels(car_data_factored$Transmission.Type)
levels(car_data_factored$Engine.Fuel.Type)
levels(car_data_factored$Driven_Wheels)
levels(car_data_factored$Engine.Cylinders)
levels(car_data_factored$Number.of.Doors)
levels(car_data_factored$Make)


#car_data_factored = one_hot(as.data.table(car_data_factored))

car_data_factored$ReleasedYearsAgo <- with(car_data_factored, 2020 - Year)

```

**Removing repetitive/unnecessary variable(s)**

```{r}
car_data_factored$Year <- NULL
```


**Modeling**

```{r}

library(dplyr)
library(ggplot2)
library(caret)
set.seed(100)
#train-test  split using 65% of the data
samplesize = round(0.65*nrow(car_data_factored), 0)
index = sample(seq_len(nrow(car_data_factored)), size = samplesize)
data_train = car_data_factored[index,]
data_test = car_data_factored[-index,]
msrp_mod = lm(MSRP ~., data_train)
summary(msrp_mod)
msrp_mod2 = lm(MSRP ~ highway.MPG + Popularity, data_test)
#summary(msrp_mod2)
#anova(msrp_mod2, msrp_mod)
```


```{r}
alias(msrp_mod)
```



**Trying Polynomial Model with AIC choice**
```{r}
MSRP_big_mod = lm(
  MSRP ~ . + I(Engine.HP ^ 2) + I(ReleasedYearsAgo ^ 2) + I(city.mpg ^ 2) + I(highway.MPG ^ 2)  + I(Popularity ^ 2), 
  data = data_train)

MSRP_mod_back_aic = step(MSRP_big_mod, direction = "backward", trace = 0)

summary(MSRP_mod_back_aic)

```



**Assumptions**


```{r}
plot_func = function(model, pointcol = "blue",linecol = "green") {
  plot(fitted(model), resid(model), col = pointcol, pch = 20, xlab = "Fitted", ylab = "Residuals")
  abline(h = 0, col = linecol, lwd = 2)

}
```

```{r}
library(car)
assumption_tester = function(model) {
  
  qqnorm(resid(model), main = "Normal Q-Q Plot", col = "darkgrey")
  qqline(resid(model), col = "dodgerblue", lwd = 2)
  
  #normality test
  print(shapiro.test(model$residuals[0:5000]))
  

  #multicollinearity
  vif = vif(model)
  print("Max VIF Value:")
  print(max(vif))
  print(vif)
  
  #Constant Variance
  plot_func(model)
  hist(model$resid)
  
}

```


```{r}
#assumption_tester(MSRP_big_mod)
```


```{r}
#alias(MSRP_mod_back_aic)
#assumption_tester(MSRP_mod_back_aic)
```



**Making model improvements**

```{r}
car_removed_predictors = lm(log(MSRP) ~ Make + Engine.Fuel.Type + log(Engine.HP) +  Transmission.Type + 
    Driven_Wheels + Number.of.Doors + 
    I(ReleasedYearsAgo^2) + I(city.mpg^2) + 
    I(highway.MPG^2) , data = data_train)
```

```{r}
assumption_tester(car_removed_predictors)
```

```{r}
alias(car_removed_predictors)
summary(car_removed_predictors)
```






```{r}
#plot( MSRP~Engine.HP, data = car_data_factored, scientific = FALSE)

#hist( car_data_factored$MSRP, scientific = FALSE)

```



**This model does not **
